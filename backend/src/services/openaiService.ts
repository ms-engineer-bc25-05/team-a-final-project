// backend/src/services/openaiService.ts
import { makeOpenAI, config } from "../config/openai";

const client = makeOpenAI();

/** OpenAI ã¸ã®ã‚·ãƒ³ãƒ—ãƒ«å•ã„åˆã‚ã›ï¼ˆçŸ­æ–‡ãƒ»ç¢ºå®šçš„ãªå¿œç­”ã«èª¿æ•´ï¼‰ */
export async function simpleChat(prompt: string): Promise<string> {
  if (!client || config.useMock) {
    return `MOCK_REPLY: ${prompt}`;
  }

  try {
    const res = await client.chat.completions.create(
      {
        model: config.model,
        messages: [
          {
            role: "system",
            content:
              "å‡ºåŠ›ã¯æ—¥æœ¬èªã€‚10æ–‡å­—ä»¥å†…ã®çŸ­æ–‡ã§ã€å¥ç‚¹ãªã—ã§è¿”ç­”ã—ã¦ãã ã•ã„ã€‚èª¬æ˜ã‚„æ³¨é‡ˆã¯ä»˜ã‘ãªã„ã“ã¨ã€‚",
          },
          { role: "user", content: prompt },
        ],
        temperature: 1,   // NOTE: æ–°ã—ã„ãƒ¢ãƒ‡ãƒ«ã§ã¯ã‚µãƒãƒ¼ãƒˆå¤–ã®ãŸã‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã§ã‚ã‚‹ï¼‘ã«ä¿®æ­£
        max_completion_tokens: 20,   // â˜… é•·æ–‡ã‚’æŠ‘åˆ¶ NOTE: æ–°ã—ã„ãƒ¢ãƒ‡ãƒ«ã«å¯¾å¿œã™ã‚‹ãŸã‚max_completion_tokensã«ç½®ãæ›ãˆ
      },
      { timeout: config.timeoutMs } // timeout ã¯ç¬¬2å¼•æ•°
    );

    const msg = res.choices?.[0]?.message?.content ?? "";
    return typeof msg === "string" ? msg : JSON.stringify(msg);
  } catch (e: any) {
    console.error("ğŸ”´ OpenAI error:");
    console.error("status:", e?.status);
    console.error("code:", e?.code);
    console.error("message:", e?.message);
    console.error("response.data:", e?.response?.data);
    throw e;
  }
}