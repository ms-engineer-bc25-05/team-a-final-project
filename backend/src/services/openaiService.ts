// backend/src/services/openaiService.ts
import OpenAI from "openai";

const API_KEY = process.env.OPENAI_API_KEY || "";
const MODEL = process.env.OPENAI_MODEL || "gpt-4o-mini";

/**
 * 10æ–‡å­—ä»¥å†…ã®ãƒ­ãƒ¼ã‚«ãƒ«çŸ­ç¸®ï¼ˆå¥èª­ç‚¹ã‚„ç©ºç™½ã¯é™¤å»ã—ã¦è©°ã‚ã‚‹ï¼‰
 */
export function localShortener(text: string, max = 10): string {
  if (!text) return "";
  const cleaned = text.replace(/\s+/g, "");
  const trimmed = cleaned.replace(/[ã€ã€‚,.!ï¼?ï¼Ÿ:ï¼š;ï¼›~ã€œ]/g, "");
  return trimmed.length <= max ? trimmed : trimmed.slice(0, max);
}

let client: OpenAI | null = null;
if (API_KEY) {
  client = new OpenAI({ apiKey: API_KEY });
}

/**
 * å¯èƒ½ãªã‚‰ OpenAI ã‚’ä½¿ã„ã€401/403/429 ãªã©ã¯ãƒ­ãƒ¼ã‚«ãƒ«çŸ­ç¸®ã¸ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã€‚
 * ä¾‹å¤–ã¯åŸºæœ¬æŠ•ã’ãšã€æœ€çµ‚çš„ã«å¿…ãšæ–‡å­—åˆ—ã‚’è¿”ã™ã€‚
 */
export async function simpleChat(prompt: string): Promise<string> {
  const safeFallback = () => localShortener(prompt);

  // APIã‚­ãƒ¼ãŒç„¡ã„å ´åˆã¯å³ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
  if (!client) return safeFallback();

  try {
    const res = await client.responses.create({
      model: MODEL,
      input: [
        { role: "system", content: "ãƒ¦ãƒ¼ã‚¶ãƒ¼æ–‡ã‚’10æ–‡å­—ä»¥å†…ã®æ—¥æœ¬èªã§çŸ­ãè¿”ã—ã¦ãã ã•ã„ã€‚è¿”ç­”ã¯çŸ­æ–‡ã®ã¿ã€‚" },
        { role: "user", content: prompt },
      ],
    });

    const out = (res as any).output_text?.trim() as string | undefined;
    const text = out || "";
    // OpenAIå¿œç­”ãŒé•·ã™ãã‚‹å ´åˆã‚‚ãƒ­ãƒ¼ã‚«ãƒ«ã§è©°ã‚ã¦10å­—ä»¥å†…ä¿è¨¼
    return text && text.length <= 10 ? text : localShortener(text || prompt);
  } catch (e: any) {
    // ãƒ­ã‚°ã ã‘æ®‹ã—ã¦ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    const status = e?.status;
    const code = e?.code;
    console.error("ğŸ”´ OpenAI error (handled in simpleChat):", { status, code, message: e?.message });

    // ã‚ˆãã‚ã‚‹ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¯¾è±¡
    if (status === 401 || status === 403 || status === 429) return safeFallback();

    // ãã‚Œä»¥å¤–ã®ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ç³»ãƒ»ä¸€æ™‚éšœå®³ãªã©ã‚‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    return safeFallback();
  }
}
